{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, Model, utils, optimizers, models\n",
    "from tensorflow.keras.layers import Conv2D,concatenate, Activation, BatchNormalization, MaxPooling2D, Dropout,Conv2DTranspose, UpSampling2D\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions\n",
    "\n",
    "Here we define the loss function, which is dice loss. We use dice loss address the problem of class imbalance.\n",
    "\n",
    "\n",
    "We also define a convolutional block to add two conv layers.\n",
    "\n",
    "\n",
    "Finally, we define the model in the get_unet function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=-1)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred, axis=-1)\n",
    "\n",
    "    return 1 - (numerator + 1) / (denominator + 1)\n",
    "\n",
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "\n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    # Expansive Path\n",
    "    u6 = UpSampling2D((2,2), interpolation='bilinear')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u7 = UpSampling2D((2,2), interpolation='bilinear')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u8 = UpSampling2D((2,2), interpolation='bilinear')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u9 = UpSampling2D((2,2), interpolation='bilinear')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data and define our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c2ab15b9f530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m#Get y patches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m#Create mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "def post_proc(mask, std):\n",
    "    ret, thresh = cv2.threshold(mask, std, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #Close gaps in mask and dilate\n",
    "    kernel_c = np.ones((2,2),np.uint8)\n",
    "    kernel_d = np.ones((5,5),np.uint8)\n",
    "\n",
    "    mask_proc = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel_c)\n",
    "    mask_proc = cv2.dilate(mask_proc,kernel_d,iterations = 1)\n",
    "    return mask_proc\n",
    "\n",
    "#Read configuration file\n",
    "with open('config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "IMG_W = config['image_width']\n",
    "IMG_H = config['image_height']\n",
    "\n",
    "win_w = config['window_width']\n",
    "win_h = config['window_height']\n",
    "\n",
    "scaled_win_w = config['model_input_width']\n",
    "scaled_win_h = config['model_input_height']\n",
    "\n",
    "num_win_x = IMG_W/win_w\n",
    "num_win_y = IMG_H/win_h\n",
    "\n",
    "image_dir = './Images/'\n",
    "mask_dir = './Masks/'\n",
    "\n",
    "img_names = os.listdir(image_dir)\n",
    "mask_names = os.listdir(mask_dir)\n",
    "\n",
    "#Due to labelling software, might need to rename the image names\n",
    "RENAME_IMAGES = False\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "#Because of annotation software, there may be a mismatch in naming\n",
    "if RENAME_IMAGES:\n",
    "    for img_name in img_names:\n",
    "        img_path_curr = os.path.join(image_dir, img_name)\n",
    "        img_path_lower = os.path.join(image_dir, img_name.lower())\n",
    "        os.rename(img_path_curr, img_path_lower)\n",
    "    #After renaming, get img_names again\n",
    "    img_names = os.listdir(image_dir)\n",
    "\n",
    "#Data Collection\n",
    "for i in tqdm(range(len(img_names)), desc='Collecting Data'):\n",
    "\n",
    "    #Obtain mask and image paths\n",
    "    mask_path = os.path.join(mask_dir, mask_names[i])\n",
    "    img_name = mask_names[i].split('_mask')[0]+'.jpg'\n",
    "    assert img_name in img_names, 'Expected {} in {}, if image filename is uppercase, use --ri = True'.format(img_name, args['images'])\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "\n",
    "    #Read mask and img in\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "    ret, thresh = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "    img = cv2.imread(img_path)\n",
    "    scaled_img = cv2.resize(img, (128, 128))/255.0\n",
    "    scaled_mask = cv2.resize(thresh, (128, 128))/255.0\n",
    "\n",
    "    X.append(scaled_img)\n",
    "    y.append(scaled_mask)\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If a model already exists we can pass its path in to further train\n",
    "MODEL_PATH = False\n",
    "\n",
    "#Hyperparameters\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "VAL_SPLIT = 0.15\n",
    "\n",
    "if not MODEL_PATH:\n",
    "    print('No model path given, creating new model')\n",
    "\n",
    "    #Model Definition\n",
    "    num_channels = 3 #bgr\n",
    "\n",
    "    inputs = layers.Input((128, 128, num_channels))\n",
    "\n",
    "    model = get_unet(inputs)\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss=dice_loss, metrics=[dice_loss,'accuracy'])\n",
    "\n",
    "else:\n",
    "    print('Model path specified, loading model')\n",
    "\n",
    "    try:\n",
    "        model = models.load_model(MODEL_PATH, compile=False) \n",
    "        model.compile(optimizer=optimizers.Adam(learning_rate=0.0005), loss=dice_loss, metrics=[dice_loss,'accuracy'])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "#reshape y\n",
    "if len(y.shape) < 4:\n",
    "    y = np.expand_dims(y, axis=3)\n",
    "\n",
    "#Shuffle\n",
    "idx = np.random.permutation(len(X))\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "\n",
    "history = model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=VAL_SPLIT)\n",
    "\n",
    "model.save('unet_model')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12,8)\n",
    "ax.plot(history.history['acc'], label='accuracy')\n",
    "ax.plot(history.history['val_acc'], label='validation_accuracy')\n",
    "ax.plot(history.history['dice_loss'], label='dice_loss')\n",
    "ax.plot(history.history['val_dice_loss'], label='validation_dice_loss')\n",
    "ax.set_xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.savefig('history.png')\n",
    "\n",
    "print('Model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_proc(mask, std):\n",
    "    ret, thresh = cv2.threshold(mask, std, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #Close gaps in mask and dilate\n",
    "    kernel_c = np.ones((2,2),np.uint8)\n",
    "    kernel_d = np.ones((5,5),np.uint8)\n",
    "\n",
    "    mask_proc = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel_c)\n",
    "    mask_proc = cv2.dilate(mask_proc,kernel_d,iterations = 1)\n",
    "    return mask_proc\n",
    "\n",
    "#Read configuration file\n",
    "with open('config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "IMG_W = config['image_width']\n",
    "IMG_H = config['image_height']\n",
    "\n",
    "win_w = config['window_width']\n",
    "win_h = config['window_height']\n",
    "\n",
    "num_win_x = int(IMG_W/win_w)\n",
    "num_win_y = int(IMG_H/win_h)\n",
    "\n",
    "#Ensure Image size divides evenly by win_w and win_h\n",
    "scaled_img_w = win_w*num_win_x\n",
    "scaled_img_h = win_h*num_win_y\n",
    "\n",
    "#Path to artifactless dataset\n",
    "image_dir = '../artifact_segmentation/artifactless/'\n",
    "model_path = './unet_model'\n",
    "#Folder to save segmented images\n",
    "output_folder = './markers'\n",
    "#Color of segmentation\n",
    "color = [0,0,255]\n",
    "#Whether to also output the mask\n",
    "OUTPUT_MASKS = True\n",
    "\n",
    "#Load model in with custom loss function\n",
    "try:\n",
    "    model = models.load_model(model_path, compile=False) \n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss=dice_loss, metrics=[dice_loss,'accuracy'])\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "img_names = os.listdir(image_dir)\n",
    "\n",
    "#Data Collection\n",
    "for img_name in tqdm(img_names, desc='Segmenting Markers'):\n",
    "    X = []\n",
    "\n",
    "    #Obtain image path\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "\n",
    "    #Read image\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    #Resize image to ensure integer number of patches fit within\n",
    "    img_scaled = cv2.resize(img, (scaled_img_w, scaled_img_h))\n",
    "\n",
    "    #Create image patches\n",
    "    cols = np.arange(0, num_win_x*win_w, win_w)\n",
    "    rows = np.arange(0, num_win_y*win_h, win_h)\n",
    "    for row in rows:\n",
    "        for col in cols:\n",
    "            win_img = img_scaled[col:col+win_w,row:row+win_w,:]/255.0\n",
    "            X.append(win_img)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "\n",
    "    #Get y patches\n",
    "    y = model.predict(X)\n",
    "\n",
    "    #Create mask\n",
    "    mask = np.zeros((num_win_x*win_w, num_win_y*win_h))\n",
    "\n",
    "    cols = np.arange(0, num_win_x*win_w, win_w)\n",
    "    rows = np.arange(0, num_win_y*win_h, win_h)\n",
    "\n",
    "    #Get scaled standard deviation of predictions\n",
    "    std = np.std(y)*255.0\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "        for j in range(len(cols)):\n",
    "            patch = y[(i*num_win_x)+j]\n",
    "            patch = np.reshape(patch, patch.shape[:2]) #remove last dimension\n",
    "            patch = post_proc(patch*255, std)\n",
    "            mask[cols[j]:cols[j]+win_w,rows[i]:rows[i]+win_h] = patch\n",
    "\n",
    "    resized_mask = cv2.resize(mask, (IMG_W, IMG_H))\n",
    "\n",
    "    #Make output image copy\n",
    "    img_o = img.copy()\n",
    "    idx = np.where(resized_mask == 255)\n",
    "    img_o[idx] = color\n",
    "\n",
    "    if OUTPUT_MASKS:\n",
    "        output_path = os.path.join(output_folder,img_name.split('.')[0] + '_mask.jpg')\n",
    "        cv2.imwrite(output_path, resized_mask)\n",
    "\n",
    "    output_path = os.path.join(output_folder,img_name.split('.')[0] + '_labelled.jpg')\n",
    "    cv2.imwrite(output_path, img_o)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
